{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OudB5by50jlI"
   },
   "source": [
    "# Sentiment Classification\n",
    "\n",
    "###Objective\n",
    "To classify user sentiments as positive or negative using Natural Language Process techniques.\n",
    "\n",
    "We generate Word Embedding and retrieve outputs of each layer with Keras based\n",
    "on the Classification task.Word embeddings are a type of word representation that allows words with similar meanings to have similar representations.\n",
    "It is a distributed representation for the text that is perhaps one of the key\n",
    "breakthroughs for the impressive performance of deep learning methods on\n",
    "challenging natural language processing problems.\n",
    "We will use the IMDb dataset to learn word embedding as we train our dataset.\n",
    "This dataset contains 50,000 movie reviews from IMDB, labeled with a sentiment\n",
    "(positive or negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xT7MKZuMRaCg"
   },
   "source": [
    "### Dataset\n",
    "- Dataset of 50,000 movie reviews from IMDB, labeled by sentiment positive (1) or negative (0)\n",
    "- Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers).\n",
    "- For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
    "- As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
    "\n",
    "Command to import data\n",
    "- `from tensorflow.keras.datasets import imdb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33637,
     "status": "ok",
     "timestamp": 1607655795267,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "JxfwbrbuKbk2",
    "outputId": "8b879b00-6eb0-443c-ff84-fdc3eda84699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EE7dDphyDNg"
   },
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTADavTzwaN2"
   },
   "outputs": [],
   "source": [
    "# Change the current working directory\n",
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sn4Ca-4axzpy"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd, numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout, MaxPooling1D, Conv1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "random_state = 1\n",
    "np.random.seed(random_state)\n",
    "tf.random.set_seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q34-Y3nRKXdO"
   },
   "source": [
    "### Import the data \n",
    "- Use `imdb.load_data()` method\n",
    "- Get train and test set\n",
    "- Take 10000 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyBfyYCKzVll"
   },
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DldivBO4LTbP"
   },
   "source": [
    "### Pad each sentence to be of same length \n",
    "- Maximum sequence length as 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E808XB4tLtic"
   },
   "outputs": [],
   "source": [
    "max_len = 300\n",
    "x_train = pad_sequences(x_train, maxlen = max_len, padding = 'pre')\n",
    "x_test =  pad_sequences(x_test, maxlen = max_len, padding = 'pre')\n",
    "\n",
    "X = np.concatenate((x_train, x_test), axis = 0)\n",
    "y = np.concatenate((y_train, y_test), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBFFCrybMSXz"
   },
   "source": [
    "### Print shape of features & labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOcyRtZfMYZd"
   },
   "source": [
    "Number of review, number of words in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1525,
     "status": "ok",
     "timestamp": 1607657585900,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "hdMCUPr7RaCm",
    "outputId": "c47fe35b-1c20-4d5e-af30-29d9569c3510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------ \n",
      "Number of reviews in training dataset: 32000\n",
      "Number of words in training dataset: 300\n",
      "Number of unique words in training dataset: 9999\n",
      "------------------------------------------------------------ \n",
      "Number of reviews in validation dataset: 8000\n",
      "Number of words in validation dataset: 300\n",
      "Number of unique words in validation dataset: 9991\n",
      "------------------------------------------------------------ \n",
      "Number of reviews in test dataset: 10000\n",
      "Number of words in test dataset: 300\n",
      "Number of unique words in test dataset: 9993\n",
      "------------------------------------------------------------ \n",
      "Unique Categories: (array([0, 1]), array([0, 1]), array([0, 1]))\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_state, shuffle = True)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size = 0.2, random_state = random_state, shuffle = True)\n",
    "\n",
    "print('---'*20, f'\\nNumber of reviews in training dataset: {x_train.shape[0]}')\n",
    "print(f'Number of words in training dataset: {x_train.shape[1]}')\n",
    "print(f'Number of unique words in training dataset: {len(np.unique(np.hstack(x_train)))}')\n",
    "\n",
    "\n",
    "print('---'*20, f'\\nNumber of reviews in validation dataset: {x_valid.shape[0]}')\n",
    "print(f'Number of words in validation dataset: {x_valid.shape[1]}')\n",
    "print(f'Number of unique words in validation dataset: {len(np.unique(np.hstack(x_valid)))}')\n",
    "\n",
    "\n",
    "print('---'*20, f'\\nNumber of reviews in test dataset: {x_test.shape[0]}')\n",
    "print(f'Number of words in test dataset: {x_test.shape[1]}')\n",
    "print(f'Number of unique words in test dataset: {len(np.unique(np.hstack(x_test)))}')\n",
    "\n",
    "\n",
    "print('---'*20, f'\\nUnique Categories: {np.unique(y_train), np.unique(y_valid), np.unique(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cNk5sDvMr3j"
   },
   "source": [
    "Number of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdXPWuOmNEbh"
   },
   "source": [
    "### Print value of any one feature and it's label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGLEdeFmNZfR"
   },
   "source": [
    "Feature value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1607657716353,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "RKFyMa28zztL",
    "outputId": "e8144433-8816-449e-d678-d0d108cce1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    1   11\n",
      "    4  454   19    4 4690 2941 1622    5 2639  481   13  197    7    4\n",
      "  636  136   11  280  725    6   58   11    4 1263   54   12  214    8\n",
      "    4  543   95   12  778    8  764   40 3904  537   42    2 8014   60\n",
      "  869    2   10   10   95   12  505   46   15   14    9   53  729    8\n",
      "  914 3989    4    2   11  756   24  405    5    4   20    2   39  454\n",
      "    8  130    4  172 4638  405 3186   25 7679  193   11    4 4587 1336\n",
      "    2 1163    7    4    2 5350 1513 1399 6777    2 6048 1880  228  978\n",
      "  934    5   60 2851 2827   95  751    4  130   50    9   31  324    7\n",
      "    6  340  275 1163 2272 4177   19 1796  228    5 4681    2  476    5\n",
      " 2129   10   10   21  279    4 7531    9   99  196   18   72   13   62\n",
      "   76  247    8   67    4 5204  499   42   51  571    8    4  109  103\n",
      "    4  277  324  131 1293  224]\n"
     ]
    }
   ],
   "source": [
    "print (x_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_85Hqm0Nb1I"
   },
   "source": [
    "Label value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1066,
     "status": "ok",
     "timestamp": 1607657710821,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "-FoehB5jNd1g",
    "outputId": "73324c4f-8c97-4540-d388-a87a48f77745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cof4LSxNxuv"
   },
   "source": [
    "### Decode the feature value to get original sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_oiAyPZOkJD"
   },
   "source": [
    "Retrieve a dictionary that contains mapping of words to their index in the IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRgOD5S2Uuvd"
   },
   "source": [
    "Use the dictionary to get the original words from the encodings, for a particular sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLGABrJoVZe6"
   },
   "source": [
    "Get the sentiment for the above sentence\n",
    "- positive (1)\n",
    "- negative (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1607658181566,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "Clsk-yK8OtzD",
    "outputId": "e6557898-b0ef-40be-ff19-afd2f2e0ba74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "Review: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> in the very first episode of friends which aired 22 <UNK> 1994 the one where monica gets a roommate there is a song playing as rachel sits in the window towards the end of the show the line that plays is if you ever need holding does anyone know the artist singing or the title of the song it is seems as if it is a great song i would love to get a copy of it thanks for the assistance i am looking for the album cd it is on so i can purchase it br br i have the shows which are available for purchase and enjoy this show over and over again it just seemed to be believable thanks for the hours of entertainment you have provided over the years\n",
      "Actual Sentiment: 1\n",
      "------------------------------------------------------------------------------------------ \n",
      " [(34704, 'fawn'), (52009, 'tsukino'), (52010, 'nunnery'), (16819, 'sonja'), (63954, 'vani'), (1411, 'woods'), (16118, 'spiders'), (2348, 'hanging'), (2292, 'woody'), (52011, 'trawling'), (52012, \"hold's\"), (11310, 'comically'), (40833, 'localized'), (30571, 'disobeying'), (52013, \"'royale\"), (40834, \"harpo's\"), (52014, 'canet'), (19316, 'aileen'), (52015, 'acurately'), (52016, \"diplomat's\"), (25245, 'rickman'), (6749, 'arranged'), (52017, 'rumbustious'), (52018, 'familiarness'), (52019, \"spider'\"), (68807, 'hahahah'), (52020, \"wood'\"), (40836, 'transvestism'), (34705, \"hangin'\"), (2341, 'bringing'), (40837, 'seamier'), (34706, 'wooded'), (52021, 'bravora'), (16820, 'grueling'), (1639, 'wooden'), (16821, 'wednesday'), (52022, \"'prix\"), (34707, 'altagracia'), (52023, 'circuitry'), (11588, 'crotch'), (57769, 'busybody'), (52024, \"tart'n'tangy\"), (14132, 'burgade'), (52026, 'thrace'), (11041, \"tom's\"), (52028, 'snuggles'), (29117, 'francesco'), (52030, 'complainers'), (52128, 'templarios'), (40838, '272')]\n"
     ]
    }
   ],
   "source": [
    "def decode_review(x, y):\n",
    "  w2i = imdb.get_word_index()                                \n",
    "  w2i = {k:(v + 3) for k, v in w2i.items()}\n",
    "  w2i['<PAD>'] = 0\n",
    "  w2i['<START>'] = 1\n",
    "  w2i['<UNK>'] = 2\n",
    "  i2w = {i: w for w, i in w2i.items()}\n",
    "\n",
    "  ws = (' '.join(i2w[i] for i in x))\n",
    "  print(f'Review: {ws}')\n",
    "  print(f'Actual Sentiment: {y}')\n",
    "  return w2i, i2w\n",
    "\n",
    "w2i, i2w = decode_review(x_train[0], y_train[0])\n",
    "\n",
    "# get first 50 key, value pairs from id to word dictionary\n",
    "print('---'*30, '\\n', list(islice(i2w.items(), 0, 50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmCjr8miXIWB"
   },
   "source": [
    "### Define model\n",
    "- Define a Sequential Model\n",
    "- Add Embedding layer\n",
    "  - Embedding layer turns positive integers into dense vectors of fixed size\n",
    "  - `tensorflow.keras` embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unique integer number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn LabelEncoder.\n",
    "  - Size of the vocabulary will be 10000\n",
    "  - Give dimension of the dense embedding as 100\n",
    "  - Length of input sequences should be 300\n",
    "- Add LSTM layer\n",
    "  - Pass value in `return_sequences` as True\n",
    "- Add a `TimeDistributed` layer with 100 Dense neurons\n",
    "- Add Flatten layer\n",
    "- Add Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Np5GxT1caFEq"
   },
   "outputs": [],
   "source": [
    "# Creating Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 256, input_length = maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(256, 5, padding = 'same', activation = 'relu', strides = 1))\n",
    "model.add(Conv1D(128, 5, padding = 'same', activation = 'relu', strides = 1))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(64, 5, padding = 'same', activation = 'relu', strides = 1))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(LSTM(75))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc4bknOobDby"
   },
   "source": [
    "### Compile the model \n",
    "- Use Optimizer as Adam\n",
    "- Use Binary Crossentropy as loss\n",
    "- Use Accuracy as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jw4RJ0CQbwFY"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sEzwazqbz3T"
   },
   "source": [
    "### Print model summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1076,
     "status": "ok",
     "timestamp": 1607658436867,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "6Hx1yxwlb2Ue",
    "outputId": "c640f1ac-4acd-40eb-e3fa-49ac0ea708cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 256)          2560000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 300, 256)          327936    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 300, 128)          163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 150, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 150, 64)           41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 75)                42000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 76        \n",
      "=================================================================\n",
      "Total params: 3,135,004\n",
      "Trainable params: 3,135,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrNIbsDZ6bQl"
   },
   "outputs": [],
   "source": [
    "# Adding callbacks\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 0)  \n",
    "mc = ModelCheckpoint('imdb_model.h5', monitor = 'val_loss', mode = 'min', save_best_only = True, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmkolKP4b-U6"
   },
   "source": [
    "### Fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55841,
     "status": "ok",
     "timestamp": 1607658677027,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "vRg3KFXLcAkk",
    "outputId": "feaffc62-446a-4007-9ab5-dde6843e4688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9540\n",
      "Epoch 00001: val_loss did not improve from 0.24832\n",
      "500/500 [==============================] - 28s 55ms/step - loss: 0.1297 - accuracy: 0.9540 - val_loss: 0.2684 - val_accuracy: 0.9026\n",
      "Epoch 2/3\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9697\n",
      "Epoch 00002: val_loss did not improve from 0.24832\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 0.0897 - accuracy: 0.9697 - val_loss: 0.3099 - val_accuracy: 0.8966\n",
      "Epoch 00002: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f988fb5ca90>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "model.fit(x_train, y_train, validation_data = (x_valid, y_valid), epochs = 3, batch_size = 64, verbose = True, callbacks = [es, mc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwLl54MXnkEA"
   },
   "source": [
    "### Evaluate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2784,
     "status": "ok",
     "timestamp": 1607658687574,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "EUqY-bD8RaDR",
    "outputId": "756bbab0-9fc0-4a7a-ea16-745cf38cad80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 13ms/step - loss: 0.2988 - accuracy: 0.8962\n",
      "Test accuracy: 89.62%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "scores = model.evaluate(x_test, y_test, batch_size = 64)\n",
    "print('Test accuracy: %.2f%%' % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2amr1tJn9Jz"
   },
   "source": [
    "### Predict on one sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3468,
     "status": "ok",
     "timestamp": 1607658720115,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "Wl4idfWR_A8E",
    "outputId": "857f57c3-8eb7-4c18-8949-fa3a86c243e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-8ec3f06dc8c9>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      4896\n",
      "           1       0.91      0.88      0.90      5104\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test)\n",
    "print(f'Classification Report:\\n{classification_report(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2071,
     "status": "ok",
     "timestamp": 1607658836700,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "pdbXlqq17W6a",
    "outputId": "311c8ef6-a9b2-4efc-e181-79df9b04ff08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------------------------------------- embedding layer ---------------------------------------- \n",
      "\n",
      "[[[-0.0427901  -0.01804712 -0.02806675 ...  0.00624817  0.06408209\n",
      "   -0.02403734]\n",
      "  [-0.07048995  0.0796249  -0.01308915 ...  0.0400336   0.05493726\n",
      "   -0.06124282]\n",
      "  [ 0.04054682  0.00713296  0.00692001 ...  0.04047054  0.03309698\n",
      "   -0.02720738]\n",
      "  ...\n",
      "  [ 0.03292023 -0.0405538   0.01924137 ... -0.07656936  0.01597329\n",
      "    0.09222866]\n",
      "  [-0.06663334 -0.01331978 -0.00673268 ... -0.02415959 -0.05999588\n",
      "   -0.03977136]\n",
      "  [-0.05858055 -0.03403356 -0.02258617 ...  0.00834998  0.04716273\n",
      "   -0.0433165 ]]]\n",
      "\n",
      " ---------------------------------------- dropout layer ---------------------------------------- \n",
      "\n",
      "[[[-0.0427901  -0.01804712 -0.02806675 ...  0.00624817  0.06408209\n",
      "   -0.02403734]\n",
      "  [-0.07048995  0.0796249  -0.01308915 ...  0.0400336   0.05493726\n",
      "   -0.06124282]\n",
      "  [ 0.04054682  0.00713296  0.00692001 ...  0.04047054  0.03309698\n",
      "   -0.02720738]\n",
      "  ...\n",
      "  [ 0.03292023 -0.0405538   0.01924137 ... -0.07656936  0.01597329\n",
      "    0.09222866]\n",
      "  [-0.06663334 -0.01331978 -0.00673268 ... -0.02415959 -0.05999588\n",
      "   -0.03977136]\n",
      "  [-0.05858055 -0.03403356 -0.02258617 ...  0.00834998  0.04716273\n",
      "   -0.0433165 ]]]\n",
      "\n",
      " ---------------------------------------- conv1d layer ---------------------------------------- \n",
      "\n",
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.02950325 0.         ... 0.         0.08746393 0.05798914]]]\n",
      "WARNING:tensorflow:5 out of the last 317 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f988f9e6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- conv1d_1 layer ---------------------------------------- \n",
      "\n",
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.918749   0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.44162643 0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.07569395 0.         0.        ]]]\n",
      "WARNING:tensorflow:6 out of the last 318 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f988f913840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- max_pooling1d layer ---------------------------------------- \n",
      "\n",
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 2.2980924  0.         0.        ]\n",
      "  [0.         0.         0.         ... 1.9305953  0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.44162643 0.         0.        ]]]\n",
      "WARNING:tensorflow:7 out of the last 319 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f988f8e91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- conv1d_2 layer ---------------------------------------- \n",
      "\n",
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 1.3286979  0.         0.        ]\n",
      "  [0.         0.59591836 0.78017455 ... 0.5434184  0.         0.        ]\n",
      "  [0.         0.3744418  0.         ... 0.80940527 0.         0.        ]]]\n",
      "WARNING:tensorflow:8 out of the last 320 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f988f89c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- max_pooling1d_1 layer ---------------------------------------- \n",
      "\n",
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 1.3286979  0.         0.        ]\n",
      "  [0.         0.59591836 0.78017455 ... 0.80940527 0.         0.        ]]]\n",
      "WARNING:tensorflow:9 out of the last 321 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f988f8e92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- lstm layer ---------------------------------------- \n",
      "\n",
      "[[ 0.18932194  0.7503545  -0.04003118 -0.06731407 -0.7852025   0.80521923\n",
      "   0.02196536  0.87556815  0.34449357  0.28188366  0.2123448   0.32762784\n",
      "  -0.68154234  0.5542655   0.03332231 -0.04936034 -0.12447736 -0.49127498\n",
      "  -0.04607897  0.00393017  0.03051372 -0.10369331 -0.54953325  0.14656205\n",
      "  -0.00108841 -0.5438158  -0.10355715 -0.57364416  0.55468446  0.5439403\n",
      "   0.17121372  0.5208187  -0.46456102  0.71584916 -0.02928456 -0.00611586\n",
      "  -0.7291987   0.33602205 -0.02698452  0.44667274 -0.04292644  0.5397462\n",
      "  -0.00612601 -0.11971071  0.0827677   0.38950962 -0.6474109   0.59276605\n",
      "  -0.26514143  0.21788326  0.0593911   0.58260316  0.3569104  -0.20322606\n",
      "  -0.03031337  0.00624237  0.5560501  -0.00399245 -0.7547673   0.22834286\n",
      "  -0.42291394  0.8471559  -0.20106283  0.729098   -0.0603046   0.07769694\n",
      "   0.33514675 -0.6664159   0.7461609  -0.08769871  0.81325656 -0.54970425\n",
      "   0.6548846   0.38692328  0.82034314]]\n",
      "WARNING:tensorflow:10 out of the last 322 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f988f8bbf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ---------------------------------------- dense layer ---------------------------------------- \n",
      "\n",
      "[[0.9902996]]\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the output of each layer in keras for a given single test sample from the trained model\n",
    "\n",
    "sample_x_test = x_test[np.random.randint(10000)]\n",
    "\n",
    "for layer in model.layers:\n",
    "    model_layer = Model(inputs = model.input, outputs = model.get_layer(layer.name).output)\n",
    "    output = model_layer.predict(sample_x_test.reshape(1,-1))\n",
    "    print('\\n','--'*20, layer.name, 'layer', '--'*20, '\\n')\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 933,
     "status": "ok",
     "timestamp": 1607658861151,
     "user": {
      "displayName": "Srikanta MC",
      "photoUrl": "",
      "userId": "07943314425583854188"
     },
     "user_tz": -330
    },
    "id": "WfhOc9X_7wp8",
    "outputId": "9f387124-07e5-4679-d85f-738e0ce57af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> what a bad movie i'm really surprised that deniro and even snipes would be associated with something like this if you're going to make a movie that involves baseball and shows scenes of baseball at least make the action look somewhat realistic why was the crowd always standing up for no particular reason during games possible spoiler and the last scene in the movie what was that we are somehow led to believe that deniro has found his way onto the field in an <UNK> uniform and that the game is even being played in a <UNK> <UNK> one of the worst ever scenes in a sports movie 3 stars out of 10\n",
      "Actual Sentiment: 0\n",
      "Predicted sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "decode_review(x_test[10], y_test[10])\n",
    "print(f'Predicted sentiment: {y_pred[10][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7ERFWTJ8AeL"
   },
   "source": [
    "Conclusion: On the sentiment classification of IMDB Dataset we achieved\n",
    "- Accuracy 90%\n",
    "- F1-Score 90%\n",
    "- Loss 24.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8H6JA_o81fD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Questions - Project 1 - Sequential Models in NLP - Sentiment Classification (1).ipynb",
   "provenance": [
    {
     "file_id": "17AWW43uddc1Q_Z_0vJq3IptihLPbrcvX",
     "timestamp": 1611148794093
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
